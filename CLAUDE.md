# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**AI GBA Player** is a universal AI gaming framework that enables Large Language Models to play Game Boy Advance games through visual understanding and decision-making. The system features a modern Django web interface with real-time chat monitoring for AI gameplay.

**Based on**: [martoast/LLM-Pokemon-Red](https://github.com/martoast/LLM-Pokemon-Red) - Original PokÃ©mon Red AI benchmark

**Key Innovations**: 
- **Simplified Architecture** - Single Django process with integrated AI service
- **Real-time Chat Interface** - Monitor AI decisions, screenshots, and actions in real-time
- **Universal Game Support** - Works with any GBA game, not just PokÃ©mon
- **Web-based Configuration** - No manual JSON editing, all settings via browser
- **Socket Communication** - Direct TCP connection between mGBA and AI service
- **Database Storage** - SQLite for configuration, no complex file management

## Core Architecture

### Simple Two-Layer System
1. **mGBA Emulator + Lua Script** (`emulator/script.lua`) - Game interface layer
2. **AI GBA Player Web Interface** (`ai_gba_player/`) - Django web app with integrated AI service

### Data Flow
```
mGBA â†’ Lua Script â†’ Socket (Port 8888) â†’ AIGameService â†’ LLM API â†’ Button Commands â†’ Back to mGBA
                                     â†“
                            Real-time Chat Interface
                         (Screenshots, AI Responses, Actions)
```

The system uses a **simplified single-process architecture** with direct socket communication, real-time chat monitoring, and database-driven configuration.

## Key Commands

### Running the AI GBA Player
```bash
# Start the web interface (MAIN COMMAND)
cd ai_gba_player
python manage.py runserver

# Access the web interface
# Open browser to: http://localhost:8000
```

### Setup Sequence (SIMPLE)
1. Start web interface: `cd ai_gba_player && python manage.py runserver`
2. Configure ROM, mGBA, and AI settings at http://localhost:8000
3. Click "Launch mGBA" or start mGBA manually
4. Click "Reset mGBA Connection" to start AI service
5. In mGBA: Tools > Script Viewer > Load `emulator/script.lua`
6. Watch AI play in real-time chat interface

### Testing Components
```bash
# Test AI service communication
python dev-tools/test-scripts/test_ai_service.py

# Test Django app
cd ai_gba_player
python manage.py test

# Test game detection and Sapphire support
python dev-tools/test-scripts/test_game_detection.py
python dev-tools/test-scripts/test_final_sapphire_flow.py

# Test mGBA connection (while Django server is running)
curl -X POST http://localhost:8000/api/restart-service/
curl http://localhost:8000/api/chat-messages/

# Memory debugging tools (load in mGBA Script Viewer)
# Load these files in mGBA Tools > Script Viewer:
# - dev-tools/memory-debugging/simple_sapphire_memory_finder.lua
# - dev-tools/memory-debugging/find_sapphire_direction.lua
```

## Project Structure (Updated)

### Active Components (Used by `python manage.py runserver`)
```
ai_gba_player/                     # Django web application (MAIN)
â”œâ”€â”€ manage.py                      # Django management command entry point
â”œâ”€â”€ ai_gba_player/                 # Django project settings directory
â”‚   â”œâ”€â”€ settings.py                # Django configuration (apps, database, paths)
â”‚   â”œâ”€â”€ urls.py                    # Main URL routing (includes API endpoints)
â”‚   â”œâ”€â”€ simple_views.py            # PRIMARY VIEW LAYER - embedded HTML + API endpoints
â”‚   â”œâ”€â”€ wsgi.py                    # WSGI application server entry point
â”‚   â””â”€â”€ asgi.py                    # ASGI application server entry point (unused)
â”œâ”€â”€ dashboard/                     # Primary Django app - ALL core functionality
â”‚   â”œâ”€â”€ ai_game_service.py         # CORE: AI service (socket server + LLM integration)
â”‚   â”œâ”€â”€ llm_client.py              # CORE: Multi-provider LLM API client 
â”‚   â”œâ”€â”€ game_detector.py           # Game detection and configuration
â”‚   â”œâ”€â”€ models.py                  # Database models (Configuration, Process, etc.)
â”‚   â”œâ”€â”€ static/dashboard/          # CSS/JS for web interface
â”‚   â”‚   â”œâ”€â”€ css/dashboard.css      # Main dashboard styling
â”‚   â”‚   â””â”€â”€ js/dashboard.js        # Frontend JavaScript (chat polling)
â”‚   â””â”€â”€ migrations/                # Database schema migrations
â”œâ”€â”€ core/                          # Memory system integration ONLY
â”‚   â”œâ”€â”€ graphiti_memory.py         # Graphiti-based autonomous learning system
â”‚   â””â”€â”€ memory_service.py          # Memory service abstraction layer
â”œâ”€â”€ db.sqlite3                     # SQLite database (configuration + process state)
â”œâ”€â”€ media/uploads/roms/            # ROM file uploads directory
â””â”€â”€ staticfiles/                   # Collected static files (Django admin + custom)

emulator/
â””â”€â”€ script.lua                     # mGBA Lua script for game control (TCP socket communication)

data/                              # AI memory and game state
â”œâ”€â”€ notepad.txt                    # Simple text-based AI memory log
â”œâ”€â”€ prompt_template.txt            # Optimized LLM prompt template
â””â”€â”€ screenshots/                   # Game screenshots for AI analysis
```

### Legacy/Unused Components (NOT used by main program)
```
api/                               # âŒ UNUSED - Legacy REST API superseded by simple_views
core/                              # âŒ UNUSED - Legacy base framework classes  
games/                             # âŒ UNUSED - Game-specific modules (replaced by simple detection)
tests/                             # âŒ UNUSED - Legacy test files
dev-tools/                         # âš ï¸  Development utilities only (not part of main program)
docs/                              # âš ï¸  Documentation only
```

## Actual Architecture (How `python manage.py runserver` Works)

### Django Application Structure
The main program follows a **simplified single-file approach**:

**1. Entry Point**: `ai_gba_player/manage.py`
- Standard Django management command entry point
- Sets `DJANGO_SETTINGS_MODULE = 'ai_gba_player.settings'`

**2. Django Project**: `ai_gba_player/ai_gba_player/`
- `settings.py`: Configures Django apps, database, static files
- `urls.py`: Routes all URLs to views in `simple_views.py` 
- `simple_views.py`: **CORE IMPLEMENTATION** - contains all views and API endpoints

**3. Main App**: `ai_gba_player/dashboard/`
- `ai_game_service.py`: Socket server + AI decision engine
- `llm_client.py`: Multi-provider LLM API wrapper
- `models.py`: Database models for configuration storage

### Key Design Decisions

**Embedded HTML Approach**: 
- All HTML/CSS/JS embedded directly in `simple_views.py`
- No separate template files needed
- Eliminates template loading complexity
- Single-file contains complete UI + API

**File-Based Configuration Fallback**:
- Primary: SQLite database via Django models  
- Secondary: `/tmp/ai_gba_player_config.json` for simple storage
- Auto-updates main `config_emulator.json` when needed

**Direct Socket Communication**:
- AI service runs as daemon thread from Django
- Direct TCP socket on port 8888 for mGBA communication
- No complex message queues or inter-process communication

## Configuration System

### Database Configuration (Primary)
All settings stored in SQLite database via Django models:
- **Configuration model**: LLM provider, API keys, cooldown settings
- **Process model**: Service status tracking
- **Web interface**: Configure everything through browser at http://localhost:8000

### JSON Configuration (Legacy/Auto-updated)
`config_emulator.json` - Automatically updated when saving AI settings through web interface

### No Manual Configuration Required
- ROM path: Set via web interface
- mGBA path: Auto-detected or set via web interface  
- API keys: Entered securely via web interface
- All settings persist in SQLite database

## Graphiti Memory System (NEW FEATURE)

### Autonomous Learning & Memory
The AI GBA Player now includes an advanced **Graphiti-powered memory system** that enables:

**ðŸŽ¯ Autonomous Objective Discovery**: AI analyzes its own responses to discover new goals
- "I need to find the Pokemon Center" â†’ Creates "find Pokemon Center" objective
- Auto-categorizes as main/side/exploration with priority scoring
- Tracks discovery location and completion status

**ðŸ§  Strategy Learning**: Remembers what button patterns work in different situations
- Records successful button sequences for specific contexts
- Tracks success rates and usage frequency
- Provides learned strategies in future similar situations

**ðŸ† Achievement Tracking**: Automatically detects and records completed objectives
- "I caught a Pikachu!" â†’ Completes "catch electric Pokemon" objective
- Maintains achievement history with completion times and locations
- Creates prerequisite chains between related objectives

**ðŸ“Š Memory-Enhanced Prompts**: LLM receives contextual memory in every decision
```
## ðŸŽ¯ Current Objectives:
  ðŸ”¥ Defeat Team Rocket leader (Priority: 9)
  â­ Find Pokemon Center to heal team (Priority: 6)

## ðŸ§  Learned Strategies:
  ðŸ’¡ talking to npc: [A, A, B] (Success: 85.7%)
  ðŸ’¡ navigating menu: [START, UP, A] (Success: 92.3%)
```

### Installation & Configuration
```bash
# Full Graphiti support (recommended)
pip install graphiti-ai>=0.3.0 neo4j>=5.0.0

# Auto-fallback if unavailable
# System uses SimpleMemorySystem automatically
```

### Architecture Integration
- **Memory Discovery**: `ai_gba_player/dashboard/ai_game_service.py` analyzes AI responses
- **Context Enhancement**: `ai_gba_player/dashboard/llm_client.py` injects memory into prompts  
- **Knowledge Storage**: `ai_gba_player/core/graphiti_memory.py` manages Graphiti/Neo4j
- **Template Integration**: `data/prompt_template.txt` includes `{memory_context}` variable

### Benefits
- **Self-improving AI**: Gets better at games over time through learning
- **Goal persistence**: Important objectives don't get forgotten
- **Strategy reuse**: Successful patterns are remembered and applied
- **Context awareness**: AI knows what it should be doing at any moment

## Prompt Optimization System

### Optimized LLM Communication
The system uses a **highly optimized prompt template** for efficient LLM communication:

- **Token Reduction**: ~906 tokens (down from ~1,200+ tokens) = **25% reduction**
- **File-based Templates**: `data/prompt_template.txt` with hot-reload capability
- **Dynamic Context**: Spatial awareness and game state injected dynamically
- **Cost Optimization**: Fewer tokens = faster responses and lower API costs

### Template Variables
```
{spatial_context}     - Dynamic location and navigation info
{recent_actions}      - Player's recent button presses  
{direction_guidance}  - Movement suggestions and context
{notepad_content}     - Long-term memory and game progress
```

### Hot-Reload Support
- Template changes detected automatically
- No service restart required for prompt updates
- Real-time prompt optimization during development

## AI Service Architecture

### AIGameService (`dashboard/ai_game_service.py`)
Single-threaded service that combines:
- **Socket Server**: Listens on port 8888 for mGBA connections
- **AI Decision Processing**: Sends screenshots to LLM and gets decisions
- **Chat Message Storage**: Stores messages for real-time web interface
- **Error Handling**: Graceful fallbacks when LLM calls fail

### LLMClient (`dashboard/llm_client.py`)
Handles API calls to different LLM providers:
- **Google Gemini**: Primary provider with function calling
- **OpenAI**: GPT-4o with vision and tools
- **Anthropic**: Claude models (future support)
- **Error Recovery**: Timeout handling and fallback responses

### Real-time Chat Interface
- **Message Types**: System, screenshot, AI response
- **Polling**: Frontend polls `/api/chat-messages/` every 2 seconds
- **Message Storage**: In-memory buffer with 100 message limit
- **Auto-scroll**: Automatic scrolling to latest messages

## Communication Architecture

### Socket Communication
- **mGBA â†” AI Service**: TCP Socket (Port 8888)
- **Protocol**: Text-based messages (ready, screenshot_data, button commands)
- **Connection Management**: Automatic reconnection handling

### Web Interface Communication  
- **Frontend â†” Backend**: HTTP API endpoints
- **Real-time Updates**: Polling-based (foundation for future WebSocket upgrade)
- **Configuration**: POST endpoints for saving settings
- **Status**: GET endpoints for service status and messages

### Message Protocol
```
mGBA â†’ AI Service: "ready"
mGBA â†’ AI Service: "screenshot_data|/path/to/screenshot.png|x|y|direction|mapId"
AI Service â†’ mGBA: "request_screenshot"
AI Service â†’ mGBA: "0,1,4" (button codes: A,B,RIGHT)
```

## LLM Integration

### Tool-Based Architecture
- **`press_button`**: Execute game controls with button arrays
- **Function Calling**: Both Google Gemini and OpenAI support tool calling
- **Error Recovery**: Fallback actions when LLM requests fail

### Context Processing
- **Screenshot Analysis**: LLM analyzes PNG images of game state
- **Game State Context**: Position, direction, map ID provided to LLM
- **Prompt Templates**: Game-specific prompts for better decision-making
- **Response Parsing**: Extract button actions from LLM tool calls

## Common Development Patterns

### Starting the System
```python
# 1. Start Django server
cd ai_gba_player && python manage.py runserver

# 2. Start AI service via web interface
curl -X POST http://localhost:8000/api/restart-service/

# 3. Check service status
curl http://localhost:8000/api/chat-messages/
```

### Configuration Management
```python
# All configuration via Django models
from dashboard.models import Configuration

# Get current config
config = Configuration.get_config()
config_dict = config.to_dict()

# Update config via web interface (saves to database)
# POST to /api/save-ai-config/ with form data
```

### Adding New LLM Providers
```python
# In dashboard/llm_client.py
def _call_new_provider_api(self, screenshot_path, context):
    # Implement new provider
    # Return standardized response format:
    return {
        "text": "AI reasoning",
        "actions": ["UP", "A"],
        "success": True,
        "error": None
    }
```

### Error Handling
- **LLM API Failures**: Automatic fallback to basic exploration actions
- **Socket Disconnections**: Graceful reconnection handling
- **Configuration Errors**: Clear error messages in web interface
- **Service Crashes**: No crash loops, clean restart capability

## Testing

### AI Service Testing
```bash
# Test socket communication
python test_ai_service.py

# Test with real mGBA connection
# 1. Start Django server: python manage.py runserver
# 2. Start AI service via web interface
# 3. Launch mGBA and load script
# 4. Monitor chat interface for real-time activity
```

### Web Interface Testing
```bash
# Test Django app
cd ai_gba_player
python manage.py test

# Test API endpoints
curl -X POST http://localhost:8000/api/restart-service/
curl http://localhost:8000/api/chat-messages/
curl -X POST http://localhost:8000/api/stop-service/
```

## Debugging

### Service Monitoring
- **Web Interface**: Real-time chat shows all AI activity
- **Django Logs**: Console output shows service status
- **API Endpoints**: Check service health via HTTP requests

### Common Issues
- **Port 8888 in use**: Only one AI service can run at a time
- **mGBA not connecting**: Ensure mGBA is running and Lua script loaded
- **API key errors**: Configure correct provider and key via web interface
- **No screenshots**: Verify mGBA has ROM loaded and script is active

### Debug Features
- **Chat Interface**: Shows all screenshots, AI responses, and actions
- **Service Status**: Real-time connection and activity monitoring
- **Error Messages**: Clear error reporting in chat interface

## Architecture Principles

The simplified system is designed with these principles:
- **Single Process**: Django manages everything - no complex multi-process coordination
- **Embedded UI**: All HTML/CSS/JS in simple_views.py - no template complexity
- **Direct Socket**: TCP connection on port 8888 for mGBA communication
- **Database-first**: Configuration stored in SQLite via Django models
- **Real-time Monitoring**: Live chat interface with polling for transparency
- **Error Recovery**: Graceful handling of failures at all levels
- **Minimal Dependencies**: No REST framework, channels, or complex middleware

## Code Organization Status (CLEANED UP)

### âœ… Active Components (Required for main program)
- `ai_gba_player/manage.py` - Django entry point
- `ai_gba_player/ai_gba_player/simple_views.py` - **CORE: All views + API endpoints**
- `ai_gba_player/dashboard/ai_game_service.py` - **CORE: Socket server + AI logic**
- `ai_gba_player/dashboard/llm_client.py` - **CORE: Multi-provider LLM client**
- `ai_gba_player/dashboard/models.py` - Database configuration storage
- `emulator/script.lua` - mGBA interface script

### âŒ Disabled/Unused Components (Safe to ignore)
- `ai_gba_player/api/` - **DISABLED in settings.py** - Legacy REST API superseded
- `core/` (root) - **NOT IMPORTED** - Legacy base framework classes
- `games/` - **NOT USED** - Game-specific modules (simplified approach used)
- `staticfiles/rest_framework/` - **REMOVED** - Unused static files cleaned up

### ðŸ”§ Simplified Architecture Benefits
- **90% less code complexity** than original multi-process design
- **Single-file UI approach** eliminates template loading overhead
- **Direct database storage** removes JSON file management complexity
- **Embedded AI service** runs as daemon thread from Django process
- **Zero external dependencies** beyond Django and LLM APIs

The system represents a **major architectural simplification** optimized for reliability and maintainability.

**Quick Start**: `cd ai_gba_player && python manage.py runserver` â†’ http://localhost:8000 ðŸš€

## Coding Conventions

This project follows strict coding standards to ensure maintainability, testability, and clean architecture:

### 1. Object-Oriented Design (OOP)
**Principle**: Proper encapsulation - functions must belong to the right class with clear responsibilities.

**Rules**:
- âœ… **Single Responsibility**: Each class has one clear purpose
- âœ… **Proper Encapsulation**: Private methods use `_` prefix, internal methods use `__` prefix
- âœ… **Method Placement**: Functions must belong to appropriate classes, not scattered as standalone functions
- âœ… **Interface Design**: Public methods provide clear APIs, implementation details are private

**Examples**:
```python
# âœ… GOOD: Proper encapsulation
class ScreenshotManager:
    def __init__(self, base_path: str):
        self._base_path = Path(base_path)
        self._current_sequence = 0
        
    def capture_screenshot(self) -> str:
        """Public API for screenshot capture"""
        filename = self._generate_filename()
        return self._save_screenshot(filename)
    
    def _generate_filename(self) -> str:
        """Private method - implementation detail"""
        self._current_sequence += 1
        return f"screenshot_{self._current_sequence:06d}.png"

# âŒ BAD: Scattered functions
def generate_screenshot_filename():  # Should be in ScreenshotManager
    pass

def validate_file_size(path):  # Should be in FileValidator class
    pass
```

### 2. Testing Strategy
**Principle**: Unit tests with mocks > integration test scripts.

**Rules**:
- âœ… **Unit Tests**: Use Django's TestCase with proper mocking
- âœ… **Mock External Dependencies**: Socket connections, file I/O, LLM APIs
- âœ… **Test Coverage**: Each public method must have corresponding tests
- âœ… **Fast Tests**: Tests run in <1 second each, no real network calls

**File Organization**:
```
ai_gba_player/
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ tests/                    # âœ… Proper test structure
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_ai_game_service.py
â”‚   â”‚   â”œâ”€â”€ test_llm_client.py
â”‚   â”‚   â””â”€â”€ test_models.py
â”‚   â”œâ”€â”€ ai_game_service.py
â”‚   â””â”€â”€ llm_client.py
â””â”€â”€ dev-tools/
    â””â”€â”€ integration_tests/        # âœ… Separate integration tests
        â””â”€â”€ test_end_to_end.py
```

**Examples**:
```python
# âœ… GOOD: Unit test with mocks
class TestAIGameService(TestCase):
    @patch('socket.socket')
    @patch('dashboard.llm_client.LLMClient')
    def test_handle_screenshot_request(self, mock_llm, mock_socket):
        service = AIGameService()
        mock_llm.return_value.analyze_game_state.return_value = {
            'actions': ['UP'], 'success': True
        }
        
        result = service._handle_screenshot_data("test_path")
        
        self.assertEqual(result, "0,0,4")  # UP action
        mock_llm.return_value.analyze_game_state.assert_called_once()

# âŒ BAD: Integration test script
def test_real_mgba_connection():  # Should be mocked unit test
    service = AIGameService()
    service.start()  # Real socket connection
    # Test with real mGBA...
```

### 3. File Size Limits
**Principle**: No single file > 2000 lines for maintainability.

**Rules**:
- âœ… **Hard Limit**: 2000 lines maximum per file
- âœ… **Soft Target**: 500-1000 lines per file
- âœ… **Logical Separation**: Split by functionality, not arbitrarily
- âœ… **Clear Imports**: Related classes can be split across files with clear import structure

**Refactoring Strategy**:
```python
# Before: monolithic llm_client.py (3000+ lines)
# After: Split into focused modules

dashboard/
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ client.py           # Core LLMClient (~800 lines)
â”‚   â”œâ”€â”€ providers.py        # Provider-specific code (~600 lines)
â”‚   â”œâ”€â”€ image_processing.py # Image enhancement (~400 lines)
â”‚   â””â”€â”€ context_builder.py  # Prompt context logic (~500 lines)
```

### 4. Code Quality Standards

**Import Organization**:
```python
# Standard library imports
import os
import sys
from pathlib import Path

# Third-party imports
import django
from django.test import TestCase

# Local application imports
from dashboard.models import Configuration
from dashboard.llm.client import LLMClient
```

**Error Handling**:
```python
# âœ… GOOD: Specific exceptions with context
class ScreenshotNotFoundError(Exception):
    """Raised when screenshot file is not available after timeout"""
    pass

def wait_for_screenshot(self, path: str) -> bool:
    try:
        return self._validate_file(path)
    except FileNotFoundError as e:
        raise ScreenshotNotFoundError(f"Screenshot not ready: {path}") from e
```

**Documentation**:
```python
def analyze_game_state(self, screenshot_path: str, context: Dict[str, Any]) -> Dict[str, Any]:
    """Analyze game state from screenshot using LLM.
    
    Args:
        screenshot_path: Absolute path to screenshot file
        context: Game state context (position, direction, etc.)
        
    Returns:
        Dict containing:
            - text: AI reasoning
            - actions: List of button actions
            - success: Boolean success flag
            - error: Error message if failed
            
    Raises:
        ScreenshotNotFoundError: If screenshot is not available after timeout
        LLMAPIError: If LLM API call fails
    """
```

### 5. Refactoring Priorities

**Immediate Actions**:
1. **Split Large Files**: Any file >2000 lines needs immediate refactoring
2. **Extract Service Classes**: Move standalone functions into appropriate service classes
3. **Add Unit Tests**: Replace integration test scripts with proper unit tests
4. **Improve Encapsulation**: Make implementation details private

**File Size Monitoring**:
```bash
# Check current file sizes
find . -name "*.py" -exec wc -l {} + | sort -nr | head -10

# Target files likely >2000 lines:
# - llm_client.py
# - ai_game_service.py  
# - Any generated Django migrations
```

These conventions ensure the codebase remains maintainable, testable, and follows Python/Django best practices.